
<h1>Introduction to GANs</h1>
On a very high level, Generative Adversarial Networks are a special class of neural network models that can be used for Image Generation,
Super Resolution, Neural Style Transfer, Image to Image Translation, Deep Fakes and so much more. The Deep Learning community is just starting to 
imagine countless new ways in which they can be put to use.

GANs were introduced in [Goodfellow et al. 2014.](https://arxiv.org/1406.2661)

Most GANs consist of two networks, a Generator that generates fake images and a discriminator that tries to tell the fake apart from the real,
The two networks continue to compete to beat each other, until the Generator is able to create such realistic Images that cannot be distiguished from
real images.
The generator takes in a random noise vector and through a series of deconvolution layers, it generates images. In conditional-generation,
the generator and discriminator are conditioned on image attributes such as captions or class labels.
The images below are all generated by a neural network, they are from Karras et al,(2017)



////



Creating GANs that work well can be quite complex, especially for new beginners, however TorchFusion makes the whole process so SIMPLE!

<h1> Standard GAN </h2>

<pre>
Step1: Imports!
import torchfusion.gan as tfgan
from torchvision.datasets import MNIST
from torchvision.transforms import transforms
from torch.optim import Adam
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.cuda as cuda
</pre>

Step2: Define transformations on the real data
<pre>

train_transformations = transforms.Compose([
    transforms.Resize(28),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

</pre>

Step3: Load the images
<pre>

batch_size = 64

train_set = MNIST(root="./data", train=True, transform=train_transformations, download=True)

train_data = DataLoader(train_set,batch_size=batch_size,shuffle=True,num_workers=4)

</pre>

Step4: Load the noise distribution

<pre>
source = tfgan.NormalDistribution(length=len(train_set),size=(100))
source_data = DataLoader(source,batch_size=batch_size,shuffle=True,num_workers=4)

</pre>

Step5: Create Generator and Discriminator

<pre>
G = tfgan.MLPGenerator(latent_size=100,output_size=(1,28,28))
D = tfgan.MLPDiscriminator(input_size=(1,28,28))

if cuda.is_available():
    G.cuda()
    D.cuda()
</pre>

Note: While Torchfusion provides in-built Generators and Discriminators, you can always define your own using pytorch modules, TorchFusion works the same.

Step6: Optimizers and loss functions

<pre>
g_optim = Adam(G.parameters(),lr=0.0002,betas=(0.5,0.999))
d_optim = Adam(D.parameters(),lr=0.0002,betas=(0.5,0.999))

#Define the loss function
loss_fn = nn.BCELoss()
</pre>

Step7: Training Time!
<pre>
if __name__ == "__main__":

    trainer = tfgan.StandardGANModel(G,D,gen_loss_fn=loss_fn,disc_loss_fn=loss_fn)

    trainer.train(train_data,source_data,g_optim,d_optim,num_epochs=200,disc_steps=1,save_interval=3000,model_dir="gan_saved_models")
</pre>

Note that, at the save_interval you specify, generated samples are displayed and saved.

More examples are linked below:
[DCGAN]()
[WGAN]()
[MNIST-DCGAN]()


<h1>Creating a Custom GAN Trainer </h1>

At the heart of torchfusion's GAN package is the BaseGANModel class that provides a number of predefined functionalities that will serve as the foundation for most of the GAN trainers you would use.

You can easily create your own custom trainers that extend the BaseGANModel, here we shall recreate the StandardGANModel as a demonstration
There are three functions you need to override when creating your own trainers.
They are __disc_train_func__ ,  __gen_train_func__ , save , show and __predict_func__

Step1: Override the BaseGANModel
<pre>
        def __init__(self, gen_model, disc_model, gen_loss_fn,disc_loss_fn,smooth_labels=False,use_cuda_if_available=True):
        super(StandardGANModel, self).__init__(gen_model, disc_model, use_cuda_if_available)
        self.gen_loss_fn = gen_loss_fn
        self.disc_loss_fn = disc_loss_fn
        self.smooth_labels = smooth_labels

</pre>
The StandardModel takes in a single network(model)

Step2: Override the __disc_train_func__
<pre>

        def __disc_train_func__(self, target, source, optimizer,running_loss, epoch, batch_num):

        for params in self.disc_model.parameters():
            params.requires_grad = True

        optimizer.zero_grad()

        if isinstance(target, list) or isinstance(target, tuple):
            x = target[0]
        else:
            x = target

        batch_size = x.size(0)

        if self.smooth_labels:
            real_labels = torch.randn(batch_size).uniform_(0.7,1.2)
            fake_labels = torch.randn(batch_size).uniform_(0.0,0.3)
        else:
            real_labels = torch.ones(batch_size)
            fake_labels = torch.zeros(batch_size)

        if self.cuda:
            x = x.cuda()
            source = source.cuda()
            real_labels = real_labels.cuda()
            fake_labels = fake_labels.cuda()

        x = Variable(x)
        source = Variable(source)
        real_labels = Variable(real_labels)
        fake_labels = Variable(fake_labels)

        outputs = self.disc_model(x)

        real_loss = self.disc_loss_fn(outputs, real_labels)
        real_loss.backward()

        generated = self.gen_model(source)
        gen_outputs = self.disc_model(generated.detach())

        fake_loss = self.disc_loss_fn(gen_outputs, fake_labels)
        fake_loss.backward()

        optimizer.step()

        d_loss = real_loss + fake_loss

        running_loss.add_(d_loss.cpu() * batch_size)

</pre>
As you can see above, the __disc_train_func__ does does not handle anything related to iterating over epochs and fetching batches,
these are done by the BaseGANModel, our train function only needs to define the logic for training and update the running_loss


Step2: Override the __gen_train_func__
<pre>

        def __gen_train_func__(self, target, source, optimizer, running_loss, epoch, batch_num):

        for params in self.disc_model.parameters():
            params.requires_grad = False

        optimizer.zero_grad()

        if isinstance(target, list) or isinstance(target, tuple):
            x = target[0]
        else:
            x = target
        batch_size = x.size(0)
        labels = torch.ones(batch_size)
        if self.smooth_labels:
            labels = torch.randn(batch_size).uniform_(0.7,1.2)

        if self.cuda:
            source = source.cuda()
            labels = labels.cuda()

        source = Variable(source)
        labels = Variable(labels)

        fake_images = self.gen_model(source)
        outputs = self.disc_model(fake_images)

        loss = self.gen_loss_fn(outputs, labels)
        loss.backward()

        optimizer.step()

        running_loss.add_(loss.cpu() * batch_size)
</pre>

Step3: Override save

<pre>

        def save(self, source, iteration):

            save_dir = os.path.join(self.model_dir, "gen_images")

            if os.path.exists(save_dir) == False:
                os.mkdir(save_dir)
            images_file = os.path.join(save_dir, "image_{}.png".format(iteration))

            if self.cuda:
                source = source.cuda()

            source = Variable(source)
            outputs = self.gen_model(source)
            vutils.save_image(outputs.cpu().data, images_file, normalize=True)


</pre>

<pre>
    def show(self, source, iteration):

        if self.cuda:
            source = source.cuda()

        source = Variable(source)
        outputs = self.gen_model(source)

        images = vutils.make_grid(outputs.cpu().data, normalize=True)

        images = np.transpose(images.numpy(), (1, 2, 0))
        plt.imshow(images)
        plt.show()

</pre>

<pre>

    def __predict_func__(self, source):

        source = Variable(source)
        if self.cuda:
            source = source.cuda()

        source = Variable(source)
        outputs = self.gen_model(source)

        return outputs

</pre>

The base model handles user inputs gracefully, both dataloaders and tensors.

As you can see above, creating custom trainers is very easy, you only need to define the logic, all common, repeative operations such as loading the data,
handling callbacks, logging, saving samples etc. This helps you focus purely on the logic as a researcher.